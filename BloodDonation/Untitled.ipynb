{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Data</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>If you're a blood donar, you are a hero to som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Blood donation camp is held on 1 of November a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Helo everyone, we are hosting a blood campaign...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We are conducting blood donation campaign on 5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Today you donate your blood and tmr when u nee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               Data  Output\n",
       "0   1  If you're a blood donar, you are a hero to som...       1\n",
       "1   2  Blood donation camp is held on 1 of November a...       1\n",
       "2   3  Helo everyone, we are hosting a blood campaign...       1\n",
       "3   4  We are conducting blood donation campaign on 5...       1\n",
       "4   5  Today you donate your blood and tmr when u nee...       1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_excel(\"Book1.xlsx\")\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "def post_to_words(raw_post):\n",
    "    post_text=BeautifulSoup(raw_post).get_text()\n",
    "    letters_only=re.sub(\"[^ a-zA-Z]\",\" \",post_text)\n",
    "    words=letters_only.lower().split()\n",
    "    stops=set(stopwords.words(\"english\"))\n",
    "    meaningful_words=[w for w in words if w not in stops]\n",
    "    return(\" \".join(meaningful_words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Post Text............\n",
      "\n",
      "Cleaning of 0 post text completed of 35\n",
      "\n",
      "Cleaning of 10 post text completed of 35\n",
      "\n",
      "Cleaning of 20 post text completed of 35\n",
      "\n",
      "Cleaning of 30 post text completed of 35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning Post Text............\\n\")\n",
    "clean_train_post=[]\n",
    "num_size=train[\"Data\"].size\n",
    "for i in range(0,num_size):\n",
    "    if(i%10==0):\n",
    "        print(\"Cleaning of %d post text completed of %d\\n\"%(i,num_size))\n",
    "    clean_train_post.append(post_to_words(train[\"Data\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words..\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35, 228)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating the bag of words..\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(analyzer=\"word\",tokenizer=None,preprocessor=None,stop_words=None,max_features=1000)\n",
    "train_data_features=vectorizer.fit_transform(clean_train_post)\n",
    "train_data_features = train_data_features.toarray()\n",
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest= RandomForestClassifier(n_estimators = 30)\n",
    "forest=forest.fit(train_data_features,train[\"Output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_excel(\"Test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_post=len(test[\"Data\"])\n",
    "clean_test_post=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Posts.......\n",
      "\n",
      "10 posts cleaned of 25 posts\n",
      "20 posts cleaned of 25 posts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{101: 1,\n",
       " 102: 1,\n",
       " 103: 1,\n",
       " 104: 1,\n",
       " 105: 1,\n",
       " 106: 1,\n",
       " 107: 0,\n",
       " 108: 0,\n",
       " 109: 0,\n",
       " 110: 0,\n",
       " 111: 0,\n",
       " 112: 0,\n",
       " 113: 0,\n",
       " 114: 0,\n",
       " 115: 0,\n",
       " 116: 1,\n",
       " 117: 1,\n",
       " 118: 1,\n",
       " 119: 1,\n",
       " 120: 1,\n",
       " 121: 0,\n",
       " 122: 0,\n",
       " 123: 1,\n",
       " 124: 0,\n",
       " 125: 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cleaning Posts.......\\n\")\n",
    "for i in range(0,num_post):\n",
    "    if((i+1)%10==0):\n",
    "        print(\"%d posts cleaned of %d posts\" %(i+1,num_post))\n",
    "    clean_post=post_to_words(test[\"Data\"][i])\n",
    "    clean_test_post.append(clean_post)\n",
    "test_data_features=vectorizer.transform(clean_test_post)\n",
    "test_data_features=test_data_features.toarray()\n",
    "result=forest.predict(test_data_features)\n",
    "out={k:v for k,v in zip(test[\"id\"],result)}\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
